# ğŸš€ PyPI Audit Score Guide ğŸ§‘â€ğŸ’»

> Written by an auditor with an unhealthy love for JSON and mathematics. If youâ€™ve ever seen someone excited about both spreadsheets *and* curly braces, thatâ€™s who wrote this. ğŸ“Šâ•ğŸ“¦

## TL;DR (Quick & Dirty Summary)
This tool audits your package metadata with the enthusiasm of an accountant at tax season. It adds points for good behavior, subtracts them by omission, then flips the math at the end so low numbers = good and high numbers = scary. ğŸ§®

- **Lower risk percent = safer âœ…**
- **Higher risk percent = sketchier â˜ ï¸**

Your **risk percent** maps neatly to a **risk level** (see table below). No actuarial degree required (but auditors still drool over this stuff). ğŸ¤“

---

## The Calculation ğŸ§®

Mathematically speaking, the process looks like this:

\[
health\_percent = \frac{\text{sum of all good scores}}{\text{sum of all weights}} \times 100
\]

\[
risk\_percent = 100 - health\_percent
\]

If math makes you sweat, just remember: 
- A high health score = â€œthis project is alive and wellâ€ ğŸ’ª
- A high risk score = â€œthis project is coughing ominouslyâ€ ğŸ˜·

Itâ€™s not rocket science. Well, unless youâ€™re literally using it in a rocket. ğŸš€

---

## Risk Levels ğŸ¯

| Risk Percent â‰¤ | Risk Level |
|---:|:---|
| **15** | **Very Low ğŸŸ¢** |
| **30** | **Low ğŸŸ¢** |
| **50** | **Medium ğŸŸ¡** |
| **70** | **High ğŸŸ ** |
| **100** | **Critical ğŸ”´** |

Use `--fail-above N` to fail builds if any packageâ€™s risk percent goes above that.  
Legacy: `--fail-below N` still checks `health_percent < N`. (Think of it as the old â€œfitness testâ€ system.)

---

## What Gets Measured ğŸ“
Hereâ€™s the full list of metrics, their weights, and what they actually mean. 

| Metric | Weight | How it earns points | Example |
|---|---:|---|---|
| Recent Release | 15 | Full points if released today; decays over a year. | Updated last week = ğŸ‘; last touched in 2015 = ğŸ‘´ |
| Release Cadence | 10 | 6+ releases in a year = full points. | A package sneezing patches monthly = âœ… |
| License Present | 10 | Full points if license exists. | MIT â†’ âœ…, â€œLicense: noneâ€ â†’ ğŸš¨ |
| OSI License | 5 | Full if OSI-style license. | Apache-2.0 = âœ… |
| Requires-Python | 8 | Full if declared. | `>=3.9` â†’ âœ… |
| Dev Status | 8 | Stable = full points; Inactive = meh. | "Production/Stable" â†’ ğŸ† |
| README | 5 | Needs to be more than a haiku. | "# MyLib" wonâ€™t cut it. |
| Maintainer Present | 5 | Someone listed. | At least one name/email. |
| Wheels | 8 | Latest ships wheels. | Saves your laptop fan from meltdown. |
| Manylinux/abi3 | 4 | Wheel works widely. | More penguins can run it. ğŸ§ |
| Py3 Wheel | 4 | Explicit support for Python 3. | Because Python 2 is a fossil. ğŸ¦– |
| Project URLs | 5 | Repo/docs/homepage present. | GitHub link = âœ… |
| CI Badge Hint | 2 | README shows CI badge. | "build passing" spotted. |
| Dependency Count | 5 | 0â€“25 deps = full, >50 = chaos. | 150 deps? Really? |
| OSV Vulns | 6 | Zero vulns = full points. | A clean bill of health. |

---

## Example Walkthrough ğŸ§¾
Say we check `hypothetical-awesome-lib`:
- Released 30 days ago â†’ **14/15**
- 3 releases this year â†’ **5/10**
- MIT License â†’ **10/10 + 5/5**
- `requires_python = ">=3.10"` â†’ **8/8**
- Stable status â†’ **8/8**
- README is a novel â†’ **5/5**
- Maintainer: yes â†’ **5/5**
- Wheels: yes, manylinux, py3 â†’ **8/8 + 4/4 + 4/4**
- URLs present â†’ **5/5**
- CI badge present â†’ **2/2**
- Dependencies: 12 â†’ **5/5**
- OSV vulns: 0 â†’ **6/6**

**health_percent** = ~95% â†’ **risk_percent** â‰ˆ 5% â†’ **Risk: Very Low ğŸŸ¢**

---

## FAQ (Frequently Argued Questions) â“
**Q. Why do you care how long the README is?**  
A. Because a README shorter than your grocery list wonâ€™t help anyone. ğŸ›’

**Q. Why not use stars or download counts?**  
A. Stars are free. Metadata isnâ€™t. â­

**Q. My library has no dependencies â€” isnâ€™t that great?**  
A. Yes. But balance matters. Otherwise single-file joke projects would be â€œVery Low Risk.â€ ğŸ˜‚

**Q. Can I tweak the weights?**  
A. Of course. But remember: if you inflate one metric too much, youâ€™ll be explaining to senior management why their favourite dashboard suddenly shows big red scores. And they *hate* red. ğŸ”´ğŸ“ˆ

---

## Operational Bits ğŸ› ï¸
- **Quality gate:** `--fail-above N` â†’ exit **2** if any package exceeds this risk percent.  
- **Legacy gate:** `--fail-below N` â†’ exit **2** if any packageâ€™s health percent < N.  
- **Operational issues:** network/PyPI hiccups â†’ exit **1**.  
- **Success:** everything peachy â†’ exit **0**. ğŸ‰

The script emits a JSON report by default and prints a TL;DR with per-metric comments. Perfect for CI logs, PR reviews, or winning arguments with your teamâ€™s resident auditor. ğŸ‘”

---

## Final Advice ğŸ§³
- Keep dependencies healthy. ğŸ  
- Pin `requires_python`. ğŸ  
- Red scores make management nervous. Keep them green unless you enjoy urgent calendar invites. ğŸ“…

